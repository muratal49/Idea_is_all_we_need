{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013f4593-0139-4f13-ab0a-27cbd30f033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/envs/idea_nlp/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/idea_nlp/lib/python3.10/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/idea_nlp/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/idea_nlp/lib/python3.10/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/idea_nlp/lib/python3.10/site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef07aae4-5cb6-48ff-9cea-66130a685b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Results: 1748270\n",
      "\n",
      "Title: A Hybrid Approach to Audio-to-Score Alignment\n",
      "Authors: [{'name': 'Agrawal, R'}, {'name': 'Dixon, S'}, {'name': 'Machine Learning for Music Discovery Workshop at International Conference on Machine Learning (ICML)'}]\n",
      "DOI: None\n",
      "Published: 2019-05-30T00:00:00\n",
      "Full Text URL: None\n",
      "\n",
      "Title: The scientific evaluation of music content analysis systems: Valid empirical foundations for future real-world impact\n",
      "Authors: [{'name': 'Grossmann, H'}, {'name': 'International Conference on Machine Learning'}, {'name': 'Maruri-Aguilar, H'}, {'name': 'Parker, B'}, {'name': 'STURM, BLT'}]\n",
      "DOI: None\n",
      "Published: 2016-02-29T12:04:33\n",
      "Full Text URL: None\n",
      "\n",
      "Title: Machine Learning for Software Engineering: Models, Methods, and Applications\n",
      "Authors: [{'name': 'Bennaceur, Amel'}, {'name': 'Meinke, Karl'}]\n",
      "DOI: 10.1145/3183440.3183461\n",
      "Published: 2018-01-01T00:00:00\n",
      "Full Text URL: None\n",
      "\n",
      "Title: Replica conditional sequential monte carlo\n",
      "Authors: [{'name': 'Doucet, A'}, {'name': 'Proceedings of the 36th International Conference on Machine Learning'}, {'name': 'Shestopaloff, AY'}]\n",
      "DOI: None\n",
      "Published: 2019-05-13T00:00:00\n",
      "Full Text URL: None\n",
      "\n",
      "Title: Validating generic metrics of fairness in game-based resource allocation scenarios with crowdsourced annotations\n",
      "Authors: [{'name': 'Grappiolo, Corrado'}, {'name': 'Martinez, Hector P.'}, {'name': 'Workshop on Optimization & Machine Learning (OPML)'}, {'name': 'Yannakakis, Georgios N.'}]\n",
      "DOI: 10.1007/978-3-642-54455-2_8\n",
      "Published: 2011-01-01T00:00:00\n",
      "Full Text URL: None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your actual API key\n",
    "API_KEY = 'bgJyXuHdGkrBKt4VsCvR0LeiwE8x39WZ'\n",
    "\n",
    "# Set the base URL\n",
    "BASE_URL = 'https://api.core.ac.uk/v3/search/works'\n",
    "\n",
    "# Define the query parameters\n",
    "params = {\n",
    "    'q': 'machine learning',\n",
    "    'page': 5,\n",
    "    'pageSize': 5  # Number of results per page\n",
    "}\n",
    "\n",
    "# Set the authorization header\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {API_KEY}'\n",
    "}\n",
    "\n",
    "# Make the GET request\n",
    "response = requests.get(BASE_URL, headers=headers, params=params)\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"Total Results:\", data.get('totalHits', 'N/A'))\n",
    "    for paper in data.get('results', []):\n",
    "        print(\"\\nTitle:\", paper.get('title'))\n",
    "        print(\"Authors:\", paper.get('authors'))\n",
    "        print(\"DOI:\", paper.get('doi'))\n",
    "        print(\"Published:\", paper.get('publishedDate'))\n",
    "        print(\"Full Text URL:\", paper.get('fullTextLink'))\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "    print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f583a50c-9c12-4294-930e-5594cff7459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/srujana_chintala/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/srujana_chintala/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Topics from LDA:\n",
      "Topic 0: 0.041*\"metric\" + 0.041*\"fair\" + 0.021*\"propos\" + 0.017*\"adhoc\" + 0.015*\"model\" + 0.013*\"alloc\" + 0.013*\"notion\" + 0.013*\"resourc\" + 0.013*\"measur\" + 0.013*\"human\"\n",
      "\n",
      "Topic 1: 0.036*\"method\" + 0.036*\"softwar\" + 0.036*\"engin\" + 0.019*\"model\" + 0.019*\"applic\" + 0.013*\"machin\" + 0.013*\"infer\" + 0.013*\"learn\" + 0.013*\"area\" + 0.013*\"benefit\"\n",
      "\n",
      "Topic 2: 0.031*\"model\" + 0.025*\"gener\" + 0.025*\"train\" + 0.014*\"resourc\" + 0.014*\"studi\" + 0.014*\"develop\" + 0.014*\"effici\" + 0.014*\"profil\" + 0.014*\"advanc\" + 0.014*\"gpu\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top Matching Papers:\n",
      "Score: 0.1829 | Title: Machine Learning for Software Engineering: Models, Methods, and Applications\n",
      "\n",
      "Score: 0.1051 | Title: The scientific evaluation of music content analysis systems: Valid empirical foundations for future real-world impact\n",
      "\n",
      "Score: 0.0726 | Title: Replica conditional sequential monte carlo\n",
      "\n",
      "‚ùì QA Answer: Matching networks for one shot learning\n"
     ]
    }
   ],
   "source": [
    "# NLP Project: Idea is All We Need\n",
    "# ----------------------------------\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Load Data from CORE API or Fallback\n",
    "# -------------------------\n",
    "API_KEY = 'bgJyXuHdGkrBKt4VsCvR0LeiwE8x39WZ'\n",
    "headers = {'Authorization': f'Bearer {API_KEY}'}\n",
    "params = {'q': 'machine learning', 'pageSize': 5}\n",
    "\n",
    "# Retry logic with fallback\n",
    "try:\n",
    "    for attempt in range(3):\n",
    "        response = requests.get('https://api.core.ac.uk/v3/search/works', headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "        print(f\"Attempt {attempt+1} failed with status {response.status_code}. Retrying in 3s...\")\n",
    "        time.sleep(3)\n",
    "\n",
    "    response_json = response.json()\n",
    "    if 'results' in response_json:\n",
    "        data = response_json['results']\n",
    "    else:\n",
    "        print(\" CORE API did not return 'results'. Using fallback mock data.\\n\")\n",
    "        data = []\n",
    "except Exception as e:\n",
    "    print(\" API failed. Reason:\", str(e))\n",
    "    data = []\n",
    "\n",
    "# Fallback data\n",
    "if not data:\n",
    "    data = [\n",
    "        {\n",
    "            \"title\": \"Sample Paper on BERT\",\n",
    "            \"abstract\": \"This paper introduces BERT, a model for NLP.\",\n",
    "            \"fullText\": \"BERT improves the state-of-the-art in many NLP tasks. Future work includes multilingual support.\",\n",
    "            \"doi\": \"10.0001/sample.doi\",\n",
    "            \"authors\": \"John Doe\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Transformers in NLP\",\n",
    "            \"abstract\": \"Transformers have revolutionized NLP tasks.\",\n",
    "            \"fullText\": \"Transformers enable parallel processing and long context understanding. Limitations include compute cost.\",\n",
    "            \"doi\": \"10.0002/sample.doi\",\n",
    "            \"authors\": \"Jane Smith\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Create DataFrame\n",
    "papers = pd.DataFrame([{ \n",
    "    'title': d['title'], \n",
    "    'abstract': d.get('abstract', ''), \n",
    "    'fullText': d.get('fullText', ''), \n",
    "    'doi': d.get('doi', ''),\n",
    "    'authors': d.get('authors', '')\n",
    "} for d in data])\n",
    "\n",
    "# -------------------------\n",
    "# Step 2: Clean and Preprocess Text\n",
    "# -------------------------\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [stemmer.stem(w) for w in tokens if w not in stop_words and len(w) > 2]\n",
    "\n",
    "papers['tokens'] = papers['abstract'].apply(preprocess)\n",
    "\n",
    "# -------------------------\n",
    "# Step 3: Topic Modeling with LDA\n",
    "# -------------------------\n",
    "from gensim import corpora, models\n",
    "\n",
    "texts = papers['tokens'].tolist()\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "lda = models.LdaModel(corpus_bow, num_topics=3, id2word=dictionary, passes=15)\n",
    "\n",
    "print(\"\\n Topics from LDA:\")\n",
    "for idx, topic in lda.print_topics(-1):\n",
    "    print(f\"Topic {idx}: {topic}\\n\")\n",
    "\n",
    "# -------------------------\n",
    "# Step 4: Semantic Search\n",
    "# -------------------------\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "abstracts = papers['abstract'].tolist()\n",
    "embeddings = model.encode(abstracts, convert_to_tensor=True)\n",
    "\n",
    "query = \"research using BERT in NLP\"\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, embeddings)[0]\n",
    "top_results = cos_scores.topk(3)\n",
    "\n",
    "print(\"üîç Top Matching Papers:\")\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    print(f\"Score: {score.item():.4f} | Title: {papers.iloc[idx.item()]['title']}\\n\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Step 5: Question Answering with BERT\n",
    "# -------------------------\n",
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "context = papers.iloc[0]['fullText']\n",
    "question = \"What is the future work discussed?\"\n",
    "\n",
    "answer = qa_pipeline(question=question, context=context)\n",
    "print(\"‚ùì QA Answer:\", answer['answer'])\n",
    "\n",
    "# -------------------------\n",
    "# Final Notes\n",
    "# -------------------------\n",
    "# Save to CSV\n",
    "# papers.to_csv(\"papers_processed.csv\", index=False)\n",
    "\n",
    "# Add enhancements: citation graph, Streamlit UI, section-specific QA, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10312c4-b1f9-4344-94b8-a02f62c2c340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (idea_nlp)",
   "language": "python",
   "name": "idea_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
